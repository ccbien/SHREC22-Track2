{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import pickle\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from utils import get_angles\n",
    "from feature_extractor import surflet_pairs_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids(ids, labels, samples_per_class):\n",
    "    label2ids = {label:[] for label in range(1, 6)}\n",
    "    res = []\n",
    "    for id in ids:\n",
    "        label = gt[id]['label']\n",
    "        label2ids[label].append(id)\n",
    "    for label in labels:\n",
    "        res += random.sample(label2ids[label], samples_per_class)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_train_data(ids, filepath, labels=[1, 2, 3, 4, 5], samples_per_class=10**9):\n",
    "    x_train, y_train = [], []\n",
    "    count = {label:0 for label in labels}\n",
    "    for id in tqdm(select_ids(ids, labels, samples_per_class)):\n",
    "        label = gt[id]['label']\n",
    "        if label in labels and count[label] < samples_per_class:\n",
    "            # hists = get_histogram(filepath=filepath % id, bins=bins, normalize=True, flatten=True, max_ratio=max_ratio)\n",
    "            hist = surflet_pairs_feature(filepath=filepath % id, n_pairs=100)\n",
    "            x_train.append(hist)\n",
    "            y_train.append(label)\n",
    "            count[label] += 1\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "def get_test_data(ids, filepath, labels=[1, 2, 3, 4, 5], samples_per_class=10**9):\n",
    "    x_test, y_test, test_ids = [], [], []\n",
    "    count = {label:0 for label in labels}\n",
    "    for id in tqdm(select_ids(ids, labels, samples_per_class)):\n",
    "        label = gt[id]['label']\n",
    "        if label in labels and count[label] < samples_per_class:\n",
    "            hist = surflet_pairs_feature(filepath=filepath % id, n_pairs=100)\n",
    "            x_test.append(hist)\n",
    "            y_test.append(label)\n",
    "            test_ids.append(id)\n",
    "            count[label] += 1\n",
    "    return x_test, y_test, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataset(labels=[1, 2, 3, 4, 5], samples_per_class=[10**9, 10**9], train_full_data=False):\n",
    "    if train_full_data:\n",
    "        train_ids = list(range(1, 46001))\n",
    "        test_ids = []\n",
    "    else:\n",
    "        train_ids, test_ids = pickle.load(open('./honv/train_test_ids.pkl', 'rb'))\n",
    "    x_train, y_train = get_train_data(\n",
    "        ids=train_ids,\n",
    "        filepath='./dataset/ply/training/pointCloud/pointCloud%d.ply',\n",
    "        labels=labels,\n",
    "        samples_per_class=samples_per_class[0],\n",
    "    )\n",
    "\n",
    "    if not train_full_data:\n",
    "        x_test, y_test, test_ids = get_test_data(\n",
    "            ids=test_ids,\n",
    "            filepath='./dataset/ply/training/pointCloud/pointCloud%d.ply',\n",
    "            labels=labels,\n",
    "            samples_per_class=samples_per_class[1],\n",
    "        )\n",
    "        return (x_train, y_train), (x_test, y_test, test_ids)\n",
    "    else:\n",
    "        return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, xs, labels):\n",
    "    return model.predict(xs)\n",
    "\n",
    "\n",
    "def evaluate(model=None, x_test=None, y_test=None, test_ids=None, labels=None, y_pred=None, save_fig=True, names=None, ):\n",
    "    assert labels is not None and y_test is not None\n",
    "    n_labels = len(labels)\n",
    "    confusion_matrix = np.zeros((n_labels, n_labels))\n",
    "    confusion_ids = [[[] for i in range(n_labels)] for i in range(n_labels)]\n",
    "    confusion_hists = [[[] for i in range(n_labels)] for i in range(n_labels)]\n",
    "    N = len(y_test)\n",
    "\n",
    "    if y_pred is None:\n",
    "        assert model is not None and x_test is not None\n",
    "        y_pred = predict(model, x_test[:N], labels)\n",
    "    for i in range(N):\n",
    "        confusion_matrix[labels.index(y_test[i]), labels.index(y_pred[i])] += 1\n",
    "        confusion_ids[labels.index(y_test[i])][labels.index(y_pred[i])].append(test_ids[i])\n",
    "        confusion_hists[labels.index(y_test[i])][labels.index(y_pred[i])].append(random.choice(x_test[i]))\n",
    "\n",
    "    pickle.dump(confusion_ids, open(join(LOGGING_PATH, 'confusion_ids.pkl'), 'wb'))\n",
    "    pickle.dump(confusion_hists, open(join(LOGGING_PATH, 'confusion_hists.pkl'), 'wb'))\n",
    "\n",
    "    acc = sum(confusion_matrix[i, i] for i in range(n_labels)) / confusion_matrix.sum()\n",
    "    confusion_matrix = confusion_matrix.astype('int32')\n",
    "     \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[names[label] for label in labels])\n",
    "    plt.rc('font', size=12)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    try:\n",
    "        ax.set_title(f'accuracy = %.4f\\nK={cf.n_neighbors}\\n\\nEach row has a sum of 1' % acc)\n",
    "    except:\n",
    "        ax.set_title(f'accuracy = %.4f\\n\\nEach row has a sum of 1' % acc)\n",
    "    disp.plot(cmap='Reds', ax=ax)\n",
    "    plt.show()\n",
    "    if save_fig:\n",
    "        fig.savefig(join(LOGGING_PATH, f'{NAME}.jpg'))\n",
    "\n",
    "    print('Accuracy:', acc)\n",
    "    return acc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])\n",
    "\n",
    "    def save(self, root):\n",
    "        text = ''\n",
    "        for attr, value in self.__dict__.items():\n",
    "            text += f'{attr} {value}\\n'\n",
    "        with open(join(root, 'config.txt'), 'w') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Config(\n",
    "    n_neighbors = 15,\n",
    "    labels=[3, 5]\n",
    ")\n",
    "\n",
    "NAME = '35_15_full'\n",
    "LOGGING_PATH = f'./SP/{NAME}/'\n",
    "os.makedirs(LOGGING_PATH, exist_ok=True)\n",
    "cf.save(LOGGING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457d5446684b454c991511413efa101d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt = pickle.load(open('./metadata/ground_truth.pkl', 'rb'))\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test, test_ids) = init_dataset(labels=cf.labels, samples_per_class=[8280, 920])\n",
    "# pickle.dump(((x_train, y_train), (x_test, y_test, test_ids)), open(join(LOGGING_PATH, 'data.pkl'), 'wb'))\n",
    "\n",
    "x_train, y_train = init_dataset(labels=cf.labels, samples_per_class=[9200, 0], train_full_data=True)\n",
    "pickle.dump((x_train, y_train), open(join(LOGGING_PATH, 'data.pkl'), 'wb'))\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test, test_ids) = pickle.load(open('./SP/35_1/data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=cf.n_neighbors)\n",
    "model.fit(x_train, y_train)\n",
    "pickle.dump(model, open(join(LOGGING_PATH, 'model.pkl'), 'wb'))\n",
    "\n",
    "# acc, confusion_matrix = evaluate(model, x_test, y_test, test_ids, cf.labels,\n",
    "#     names={3:'sphere', 5:'torus'}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_ids = pickle.load(open(f'{LOGGING_PATH}/confusion_ids.pkl', 'rb'))\n",
    "# confusion_hists = pickle.load(open(f'./{LOGGING_PATH}/confusion_hists.pkl', 'rb'))\n",
    "\n",
    "# os.makedirs(join(LOGGING_PATH, 'confusion/ply/'), exist_ok=True)\n",
    "# os.makedirs(join(LOGGING_PATH, 'confusion/hist/'), exist_ok=True)\n",
    "\n",
    "# names = ['sphere', 'torus']\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         N = len(confusion_ids[i][j])\n",
    "#         indices = random.sample(list(range(N)), min(N, 5))\n",
    "#         for index in indices:\n",
    "#             id = confusion_ids[i][j][index]\n",
    "#             hist = confusion_hists[i][j][index]\n",
    "#             src = f'./dataset/ply/training/pointCloud/pointCloud{id}.ply'\n",
    "#             dst = join(LOGGING_PATH, f'confusion/ply/{names[i]}_{names[j]}_{id}.ply')\n",
    "#             shutil.copy(src, dst)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a50171a6c5550046c047d5886c9bc3e038e1f79a718c8e4171509d576ad3f4ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('torch-lts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
