{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import random\n",
    "import pickle\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from utils import get_angles\n",
    "from feature_extractor import surflet_pairs_feature, get_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(hists=None, **kwargs):\n",
    "    if hists is None:\n",
    "        hists = get_histogram(**kwargs)\n",
    "    for hist in hists:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(hist, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# id = random.choice(list(range(1, 46001)))\n",
    "# # plot_histogram(filepath=f'dataset/ply/training/pointCloud/pointCloud{id}.ply', normalize=False)\n",
    "# plot_histogram(filepath=f'dataset/ply/training/pointCloud/pointCloud{id}.ply', normalize=True, max_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids(ids, labels, samples_per_class):\n",
    "    label2ids = {label:[] for label in range(1, 6)}\n",
    "    res = []\n",
    "    for id in ids:\n",
    "        label = gt[id]['label']\n",
    "        label2ids[label].append(id)\n",
    "    for label in labels:\n",
    "        res += random.sample(label2ids[label], samples_per_class)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_train_data(ids, filepath, bins=10, max_ratio=0.8, labels=[1, 2, 3, 4, 5], samples_per_class=10**9):\n",
    "    x_train, y_train = [], []\n",
    "    count = {label:0 for label in labels}\n",
    "    for id in tqdm(select_ids(ids, labels, samples_per_class)):\n",
    "        label = gt[id]['label']\n",
    "        if label in labels and count[label] < samples_per_class:\n",
    "            hists = get_histogram(filepath=filepath % id, bins=bins, normalize=True, flatten=True, max_ratio=max_ratio)\n",
    "            x_train += hists\n",
    "            y_train += [label for i in range(len(hists))]\n",
    "            count[label] += 1\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "\n",
    "def get_test_data(ids, filepath, bins=10, max_ratio=0.8, labels=[1, 2, 3, 4, 5], samples_per_class=10**9):\n",
    "    x_test, y_test, test_ids = [], [], []\n",
    "    count = {label:0 for label in labels}\n",
    "    for id in tqdm(select_ids(ids, labels, samples_per_class)):\n",
    "        label = gt[id]['label']\n",
    "        if label in labels and count[label] < samples_per_class:\n",
    "            hists = get_histogram(filepath=filepath % id, bins=bins, normalize=True, flatten=True, max_ratio=max_ratio)\n",
    "            x_test.append(np.array(hists))\n",
    "            y_test.append(label)\n",
    "            test_ids.append(id)\n",
    "            count[label] += 1\n",
    "    return x_test, y_test, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataset(bins, max_ratio, labels=[1, 2, 3, 4, 5], samples_per_class=[10**9, 10**9], train_full_data=False):\n",
    "    # train_ids = []\n",
    "    # test_ids = []\n",
    "    # for label in range(1, 6):\n",
    "    #     ids = list(label2ids[label])\n",
    "    #     random.shuffle(ids)\n",
    "    #     pos = int(len(ids) * 0.9)\n",
    "    #     train_ids += ids[:pos]\n",
    "    #     test_ids += ids[pos:]\n",
    "    if train_full_data:\n",
    "        train_ids = list(range(1, 46001))\n",
    "        test_ids = []\n",
    "    else:\n",
    "        train_ids, test_ids = pickle.load(open('./honv/train_test_ids.pkl', 'rb'))\n",
    "    x_train, y_train = get_train_data(\n",
    "        train_ids,\n",
    "        './dataset/ply/training/pointCloud/pointCloud%d.ply',\n",
    "        bins=bins,\n",
    "        max_ratio=max_ratio,\n",
    "        labels=labels,\n",
    "        samples_per_class=samples_per_class[0],\n",
    "    )\n",
    "\n",
    "    if not train_full_data:\n",
    "        x_test, y_test, test_ids = get_test_data(\n",
    "            test_ids,\n",
    "            './dataset/ply/training/pointCloud/pointCloud%d.ply',\n",
    "            bins=bins,\n",
    "            max_ratio=max_ratio,\n",
    "            labels=labels,\n",
    "            samples_per_class=samples_per_class[1],\n",
    "        )\n",
    "        return (x_train, y_train), (x_test, y_test, test_ids)\n",
    "    else:\n",
    "        return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, xs, labels, honv=True):\n",
    "    if not honv: \n",
    "        return model.predict(xs)\n",
    "    counts = [len(x) for x in xs]\n",
    "    data = []\n",
    "    data = np.concatenate(xs, axis=0)\n",
    "    probs = model.predict_proba(data)\n",
    "\n",
    "    pred = []\n",
    "    head = 0\n",
    "    for count in counts:\n",
    "        p = probs[head:head+count, :].sum(axis=0)\n",
    "        pred.append(labels[p.argmax()])\n",
    "        head += count\n",
    "    return pred\n",
    "\n",
    "\n",
    "def evaluate(model=None, x_test=None, y_test=None, test_ids=None, labels=None, y_pred=None, save_fig=True, names=None, save_con=False):\n",
    "    assert labels is not None and y_test is not None\n",
    "    n_labels = len(labels)\n",
    "    confusion_matrix = np.zeros((n_labels, n_labels))\n",
    "    if save_con:\n",
    "        confusion_ids = [[[] for i in range(n_labels)] for i in range(n_labels)]\n",
    "        confusion_hists = [[[] for i in range(n_labels)] for i in range(n_labels)]\n",
    "    N = len(y_test)\n",
    "\n",
    "    if y_pred is None:\n",
    "        assert model is not None and x_test is not None\n",
    "        y_pred = predict(model, x_test[:N], labels)\n",
    "    for i in range(N):\n",
    "        confusion_matrix[labels.index(y_test[i]), labels.index(y_pred[i])] += 1\n",
    "        if save_con:\n",
    "            confusion_ids[labels.index(y_test[i])][labels.index(y_pred[i])].append(test_ids[i])\n",
    "            confusion_hists[labels.index(y_test[i])][labels.index(y_pred[i])].append(random.choice(x_test[i]))\n",
    "\n",
    "    if save_con:\n",
    "        pickle.dump(confusion_ids, open(join(LOGGING_PATH, 'confusion_ids.pkl'), 'wb'))\n",
    "        pickle.dump(confusion_hists, open(join(LOGGING_PATH, 'confusion_hists.pkl'), 'wb'))\n",
    "\n",
    "    acc = sum(confusion_matrix[i, i] for i in range(n_labels)) / confusion_matrix.sum()\n",
    "    confusion_matrix = confusion_matrix.astype('int32')\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[names[label] for label in labels])\n",
    "    plt.rc('font', size=12)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    try:\n",
    "        ax.set_title(f'accuracy = %.4f\\nK={cf.n_neighbors}\\nmax_ratio={cf.max_ratio}\\nbins={cf.bins}\\n\\nEach row has a sum of 1' % acc)\n",
    "    except:\n",
    "        ax.set_title(f'accuracy = %.4f\\n\\nEach row has a sum of 1' % acc)\n",
    "    disp.plot(cmap='Reds', ax=ax)\n",
    "    plt.show()\n",
    "    if save_fig:\n",
    "        fig.savefig(join(LOGGING_PATH, f'{NAME}.jpg'))\n",
    "\n",
    "    print('Accuracy:', acc)\n",
    "    return acc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key in kwargs:\n",
    "            setattr(self, key, kwargs[key])\n",
    "\n",
    "    def save(self, root):\n",
    "        text = ''\n",
    "        for attr, value in self.__dict__.items():\n",
    "            text += f'{attr} {value}\\n'\n",
    "        with open(join(root, 'config.txt'), 'w') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = Config(\n",
    "    bins=25,\n",
    "    max_ratio=0.8,\n",
    "    n_neighbors = 5,\n",
    "    labels=[2, 4]\n",
    ")\n",
    "\n",
    "NAME = 'cyl-cone_25_08_05_full'\n",
    "LOGGING_PATH = f'./honv/{NAME}/'\n",
    "os.makedirs(LOGGING_PATH, exist_ok=True)\n",
    "cf.save(LOGGING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c546298cb84f89b47950af1f44179c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt = pickle.load(open('./metadata/ground_truth.pkl', 'rb'))\n",
    "# for id in range(1, 46001):\n",
    "#     if gt[id]['label'] == 5:\n",
    "#         gt[id]['label'] = 3\n",
    "#     if gt[id]['label'] == 4:\n",
    "#         gt[id]['label'] = 2\n",
    "    # if gt[id]['label'] != 1:\n",
    "    #     gt[id]['label'] = 2\n",
    "\n",
    "# Train, test\n",
    "# (x_train, y_train), (x_test, y_test, test_ids) = init_dataset(bins=cf.bins, max_ratio=cf.max_ratio, labels=cf.labels, samples_per_class=[8280*2, 920*2])\n",
    "# pickle.dump(((x_train, y_train), (x_test, y_test, test_ids)), open(join(LOGGING_PATH, 'data.pkl'), 'wb'))\n",
    "\n",
    "# Train only\n",
    "x_train, y_train = init_dataset(bins=cf.bins, max_ratio=cf.max_ratio, labels=cf.labels, samples_per_class=[9200, 0], train_full_data=True)\n",
    "# pickle.dump((x_train, y_train), open(join(LOGGING_PATH, 'data.pkl'), 'wb'))\n",
    "\n",
    "# Reuse\n",
    "# (x_train, y_train), (x_test, y_test, test_ids) = pickle.load(open(f'./honv/2_class_25_08_05/data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=cf.n_neighbors)\n",
    "model.fit(x_train, y_train)\n",
    "pickle.dump(model, open(join(LOGGING_PATH, 'model.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, confusion_matrix = evaluate(model, x_test, y_test, test_ids, cf.labels,\n",
    "    # names={1:'plane', 2:'cylinder, cone', 3:'sphere, torus'}\n",
    "    names={2:'cylinder, cone', 3:'sphere, torus'},\n",
    "    save_con=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_ids = pickle.load(open(f'{LOGGING_PATH}/confusion_ids.pkl', 'rb'))\n",
    "confusion_hists = pickle.load(open(f'./{LOGGING_PATH}/confusion_hists.pkl', 'rb'))\n",
    "\n",
    "os.makedirs(join(LOGGING_PATH, 'confusion/ply/'), exist_ok=True)\n",
    "os.makedirs(join(LOGGING_PATH, 'confusion/hist/'), exist_ok=True)\n",
    "\n",
    "names = ['cylinder', 'cone']\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        N = len(confusion_ids[i][j])\n",
    "        indices = random.sample(list(range(N)), min(N, 5))\n",
    "        for index in indices:\n",
    "            id = confusion_ids[i][j][index]\n",
    "            hist = confusion_hists[i][j][index]\n",
    "            src = f'./dataset/ply/training/pointCloud/pointCloud{id}.ply'\n",
    "            dst = join(LOGGING_PATH, f'confusion/ply/{names[i]}_{names[j]}_{id}.ply')\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.title(f'{names[i]}_{names[j]}_{id}')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(hist.reshape((cf.bins, cf.bins)), cmap='gray')\n",
    "            plt.savefig(join(LOGGING_PATH, f'confusion/hist/{names[i]}_{names[j]}_{id}.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root1 = './honv/4_class_25_08_05/'\n",
    "root2 = './SP/35_30/'\n",
    "cf1 = Config(bins=25, max_ratio=0.8, n_neighbors=5, labels=[1, 2, 3, 4])\n",
    "model1 = pickle.load(open(join(root1, 'model.pkl'), 'rb'))\n",
    "\n",
    "cf2 = Config(n_neighbors=30, labels=[3, 5])\n",
    "model2 = pickle.load(open(join(root2, 'model.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (x_test1, y_test1, test_ids1) = pickle.load(open(join(root1, 'data.pkl'), 'rb'))\n",
    "_, (x_test2, y_test2, test_ids2) = pickle.load(open(join(root2, 'data.pkl'), 'rb'))\n",
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = {}\n",
    "for id, label in zip(test_ids1, predict(model1, x_test1, cf1.labels, honv=True)):\n",
    "    y_pred1[id] = label\n",
    "\n",
    "y_pred2 = {}\n",
    "for id, label in zip(test_ids2, predict(model2, x_test2, cf2.labels, honv=False)):\n",
    "    y_pred2[id] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_combined = []\n",
    "for id in test_ids1:\n",
    "    if y_pred1[id] in [1, 2, 4]:\n",
    "        y_combined.append(y_pred1[id])\n",
    "    else:\n",
    "        try:\n",
    "            y_combined.append(y_pred2[id])\n",
    "        except:\n",
    "            y_combined.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, confusion_matrix = evaluate(\n",
    "    y_test=y_test1, y_pred=y_combined,\n",
    "    save_fig=False, save_con=False,\n",
    "    labels=[1, 2, 3, 4, 5],\n",
    "    names=['', 'plane', 'cylinder', 'sphere', 'cone', 'torus']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf1 = Config(bins=20, max_ratio=0.8, n_neighbors=3, labels=[1, 2, 3, 4, 5])\n",
    "# model1 = pickle.load(open('./honv/full/12345_20_80_3/model.pkl', 'rb'))\n",
    "\n",
    "# cf2 = Config(bins=10, max_ratio=0.7, n_neighbors=5, labels=[3, 5])\n",
    "# model2 = pickle.load(open('./honv/full/35_10_70_5/model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test1, _ = get_test_data(list(range(1, 926)), './dataset/ply/test/pointCloud/pointCloud%d.ply', bins=20, max_ratio=0.8)\n",
    "# x_test2, _ = get_test_data(list(range(1, 926)), './dataset/ply/test/pointCloud/pointCloud%d.ply', bins=10, max_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1 = predict(model1, x_test1, [1, 2, 3, 4, 5])\n",
    "# y_pred2 = predict(model2, x_test2, [3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_combined = []\n",
    "# j = 0\n",
    "# for i in range(len(x_test1)):\n",
    "#     if y_pred1[i] in [1, 2, 4]:\n",
    "#         y_combined.append(y_pred1[i])\n",
    "#     else:\n",
    "#         y_combined.append(y_pred1[i])\n",
    "#         # y_combined.append(y_pred2[j])\n",
    "#         # j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = {}\n",
    "# for i, y in enumerate(y_combined):\n",
    "#     test_labels[i + 1] = y\n",
    "# pickle.dump(test_labels, open('test_labels_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = pickle.load(open('./test_labels_2.pkl', 'rb'))\n",
    "# print(test_labels[1]) # test_id: 1..925 --> label: 1..5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def foo():\n",
    "#     names = ['', 'plane', 'cylinder', 'sphere', 'cone','torus']\n",
    "#     x = [names[test_labels[i]] for i in range(1, 926)]\n",
    "#     with open('test_labels.txt', 'w') as f:\n",
    "#         f.write('\\n'.join(x))\n",
    "\n",
    "# foo()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a50171a6c5550046c047d5886c9bc3e038e1f79a718c8e4171509d576ad3f4ca"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('torch-lts')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
